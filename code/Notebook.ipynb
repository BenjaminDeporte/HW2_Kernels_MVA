{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bb08c5f",
   "metadata": {},
   "source": [
    "# Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3853bc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle as pkl\n",
    "from scipy import optimize\n",
    "from scipy.linalg import cho_factor, cho_solve\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import plotClassification, plotRegression, plot_multiple_images, generateRings, scatter_label_points, loadMNIST\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b62e00",
   "metadata": {},
   "source": [
    "## Loading the data\n",
    "\n",
    "The file 'classification_datasets' contains 3 small classification datasets:\n",
    "    \n",
    "    - dataset_1: mixture of two well separated gaussians\n",
    "    - dataset_2: mixture of two gaussians that are not separeted\n",
    "    - dataset_3: XOR dataset that is non-linearly separable.\n",
    "   \n",
    "Each dataset is a hierarchical dictionary with the following structure:\n",
    "        \n",
    "        dataset = {'train': {'x': data, 'y':label}\n",
    "                    'test': {'x': data, 'y':label}\n",
    "                  }\n",
    "The data $x$ is an $N$ by $2$ matrix, while the label $y$ is a vector of size $N$. \n",
    "\n",
    "Only the third dateset is used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60200f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('datasets/classification_datasets', 'rb')\n",
    "datasets = pkl.load(file)\n",
    "file.close()\n",
    "fig, ax = plt.subplots(1,3, figsize=(20, 5))\n",
    "for i, (name, dataset) in enumerate(datasets.items()):\n",
    "    \n",
    "    plotClassification(dataset['train']['x'], dataset['train']['y'], ax=ax[i])\n",
    "    ax[i].set_title(name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61db8dd7",
   "metadata": {},
   "source": [
    "## III- Kernel SVC \n",
    "### 1- Implementing the Gaussian Kernel\n",
    "Implement the method 'kernel' of the class RBF and linear below, which takes as input two data matrices $X$ and $Y$ of size $N\\times d$ and $M\\times d$ and returns a gramm matrix $G$ of shape $N\\times M$ whose components are $k(x_i,y_j) = \\exp(-\\Vert x_i-y_i\\Vert^2/(2\\sigma^2))$ for the RBF kernel and $k(x_i,y_j)= x_i^{\\top}y_j$ for the linear kernel. (The fastest solution does not use any for loop!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f1edb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RBF:\n",
    "    def __init__(self, sigma=1.):\n",
    "        self.sigma = sigma  ## the variance of the kernel\n",
    "    def kernel(self,X,Y):\n",
    "        ## Input vectors X and Y of shape Nxd and Mxd\n",
    "        return    ## Matrix of shape NxM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91496c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear:\n",
    "    def kernel(self,X,Y):\n",
    "        ## Input vectors X and Y of shape Nxd and Mxd\n",
    "        return ## Matrix of shape NxM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c925020",
   "metadata": {},
   "source": [
    "\n",
    "### 2- Implementing the classifier\n",
    "Implement the methods 'fit' and 'separating_function' of the class KernelSVC below to learn the Kernel Support Vector Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae012f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KernelSVC:\n",
    "    \n",
    "    def __init__(self, C, kernel, epsilon = 1e-3):\n",
    "        self.type = 'non-linear'\n",
    "        self.C = C                               \n",
    "        self.kernel = kernel        \n",
    "        self.alpha = None\n",
    "        self.support = None # support vectors\n",
    "        self.epsilon = epsilon\n",
    "        self.norm_f = None\n",
    "       \n",
    "    \n",
    "    def fit(self, X, y):\n",
    "       #### You might define here any variable needed for the rest of the code\n",
    "        N = len(y)\n",
    "\n",
    "        # Lagrange dual problem\n",
    "        def loss(alpha):\n",
    "            return  #'''--------------dual loss ------------------ '''\n",
    "\n",
    "        # Partial derivate of Ld on alpha\n",
    "        def grad_loss(alpha):\n",
    "            return # '''----------------partial derivative of the dual loss wrt alpha -----------------'''\n",
    "\n",
    "\n",
    "        # Constraints on alpha of the shape :\n",
    "        # -  d - C*alpha  = 0\n",
    "        # -  b - A*alpha >= 0\n",
    "\n",
    "        fun_eq = lambda alpha:  # '''----------------function defining the equality constraint------------------'''        \n",
    "        jac_eq = lambda alpha:    #'''----------------jacobian wrt alpha of the  equality constraint------------------'''\n",
    "        fun_ineq = lambda alpha:   # '''---------------function defining the inequality constraint-------------------'''     \n",
    "        jac_ineq = lambda alpha:   # '''---------------jacobian wrt alpha of the  inequality constraint-------------------'''\n",
    "        \n",
    "        constraints = ({'type': 'eq',  'fun': fun_eq, 'jac': jac_eq},\n",
    "                       {'type': 'ineq', \n",
    "                        'fun': fun_ineq , \n",
    "                        'jac': jac_ineq})\n",
    "\n",
    "        optRes = optimize.minimize(fun=lambda alpha: loss(alpha),\n",
    "                                   x0=np.ones(N), \n",
    "                                   method='SLSQP', \n",
    "                                   jac=lambda alpha: grad_loss(alpha), \n",
    "                                   constraints=constraints)\n",
    "        self.alpha = optRes.x\n",
    "\n",
    "        ## Assign the required attributes\n",
    "\n",
    "        \n",
    "        self.support =  #'''------------------- A matrix with each row corresponding to support vectors ------------------'''\n",
    "        \n",
    "        self.b =  #''' -----------------offset of the classifier------------------ '''\n",
    "        self.norm_f = # '''------------------------RKHS norm of the function f ------------------------------'''\n",
    "\n",
    "\n",
    "    ### Implementation of the separting function $f$ \n",
    "    def separating_function(self,x):\n",
    "        # Input : matrix x of shape N data points times d dimension\n",
    "        # Output: vector of size N\n",
    "        return \n",
    "    \n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\" Predict y values in {-1, 1} \"\"\"\n",
    "        d = self.separating_function(X)\n",
    "        return 2 * (d+self.b> 0) - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2129641d-a03c-4d4c-85fd-52657901c5a1",
   "metadata": {},
   "source": [
    "# 2 b- Implementing the visualization function\n",
    "Implement the function plotClassification that takes new data as input and the model, then displays separating function and margins along with misclassified points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b807d9-df4c-4335-aaa6-a9bda19ddb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as pltcolors\n",
    "import seaborn as sns\n",
    "\n",
    "def plotHyperSurface(ax, xRange, model, intercept, label, color='grey', linestyle='-', alpha=1.):\n",
    "    #xx = np.linspace(-1, 1, 100)\n",
    "    if model.type=='linear':\n",
    "        xRange = np.array(xRange)\n",
    "        yy = -(model.w[0] / model.w[1]) * xRange  - intercept/model.w[1]\n",
    "        ax.plot(xRange, yy, color=color, label=label, linestyle=linestyle)\n",
    "    else:\n",
    "        xRange = np.linspace(xRange[0], xRange[1], 100)\n",
    "        X0, X1 = np.meshgrid(xRange, xRange)\n",
    "        xy = np.vstack([X0.ravel(), X1.ravel()]).T\n",
    "        Y30 = model.separating_function(xy).reshape(X0.shape) + intercept\n",
    "        ax.contour(X0, X1, Y30, colors=color, levels=[0.], alpha=alpha, linestyles=[linestyle]);\n",
    "\n",
    "\n",
    "def plotClassification(X, y, model=None, label='',  separatorLabel='Separator', \n",
    "            ax=None, bound=[[-1., 1.], [-1., 1.]]):\n",
    "    \"\"\" Plot the SVM separation, and margin \"\"\"\n",
    "    colors = ['blue','red']\n",
    "    labels = [1,-1]\n",
    "    cmap = pltcolors.ListedColormap(colors)\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(1, figsize=(11, 7))\n",
    "    for k, label in enumerate(labels):\n",
    "        im = ax.scatter(X[y==label,0], X[y==label,1],  alpha=0.5,label='class '+str(label))\n",
    "\n",
    "    if model is not None:\n",
    "        # Plot the seprating function\n",
    "        plotHyperSurface(ax, bound[0], model, model.b, separatorLabel)\n",
    "        if model.support is not None:\n",
    "            ax.scatter(model.support[:,0], model.support[:,1], label='Support', s=80, facecolors='none', edgecolors='r', color='r')\n",
    "            print(\"Number of support vectors = %d\" % (len(model.support)))\n",
    "        \n",
    "        # Plot the margins\n",
    "        intercept_neg = ### compute the intercept for the negative margin\n",
    "        intercept_pos = ### compute the intercept for the positive margin\n",
    "        xx = np.array(bound[0])\n",
    "        plotHyperSurface(ax, xx, model, intercept_neg , 'Margin -', linestyle='-.', alpha=0.8)\n",
    "        plotHyperSurface(ax, xx, model, intercept_pos , 'Margin +', linestyle='--', alpha=0.8)\n",
    "            \n",
    "        # Plot points on the wrong side of the margin\n",
    "        wrong_side_points = # find wrong points\n",
    "        ax.scatter(wrong_side_points[:,0], wrong_side_points[:,1], label='Beyond the margin', s=80, facecolors='none', \n",
    "               edgecolors='grey', color='grey')  \n",
    "        \n",
    "    ax.legend(loc='upper left')\n",
    "    ax.grid()\n",
    "    ax.set_xlim(bound[0])\n",
    "    ax.set_ylim(bound[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86328951",
   "metadata": {},
   "source": [
    "### 3- Fitting the classifier\n",
    "\n",
    "Run the code block below to fit the classifier and report its output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ff8e38",
   "metadata": {},
   "source": [
    "### Dataset 1\n",
    "#### Linear classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4963bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "C=1.\n",
    "kernel = Linear().kernel\n",
    "model = KernelSVC(C=C, kernel=kernel, epsilon=1e-14)\n",
    "train_dataset = datasets['dataset_1']['train']\n",
    "model.fit(train_dataset['x'], train_dataset['y'])\n",
    "plotClassification(train_dataset['x'], train_dataset['y'], model, label='Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69cbbe52",
   "metadata": {},
   "source": [
    "#### Gaussian classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae87426",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 1.5\n",
    "C=1.\n",
    "kernel = RBF(sigma).kernel\n",
    "model = KernelSVC(C=C, kernel=kernel, epsilon=1e-14)\n",
    "train_dataset = datasets['dataset_1']['train']\n",
    "model.fit(train_dataset['x'], train_dataset['y'])\n",
    "plotClassification(train_dataset['x'], train_dataset['y'], model, label='Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45732d89",
   "metadata": {},
   "source": [
    "### Dataset 2\n",
    "#### Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e677328d",
   "metadata": {},
   "outputs": [],
   "source": [
    "C=.1\n",
    "kernel = Linear().kernel\n",
    "model = KernelSVC(C=C, kernel=kernel, epsilon=1e-14)\n",
    "train_dataset = datasets['dataset_2']['train']\n",
    "model.fit(train_dataset['x'], train_dataset['y'])\n",
    "plotClassification(train_dataset['x'], train_dataset['y'], model, label='Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0fcda5",
   "metadata": {},
   "source": [
    "#### Gaussian SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a801b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 1.5\n",
    "C=1.\n",
    "kernel = RBF(sigma).kernel\n",
    "model = KernelSVC(C=C, kernel=kernel, epsilon=1e-14)\n",
    "train_dataset = datasets['dataset_2']['train']\n",
    "model.fit(train_dataset['x'], train_dataset['y'])\n",
    "plotClassification(train_dataset['x'], train_dataset['y'], model, label='Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816e72a0",
   "metadata": {},
   "source": [
    "### Dataset 3\n",
    "#### Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a5391f",
   "metadata": {},
   "outputs": [],
   "source": [
    "C=1.\n",
    "kernel = Linear().kernel\n",
    "model = KernelSVC(C=C, kernel=kernel, epsilon=1e-14)\n",
    "train_dataset = datasets['dataset_3']['train']\n",
    "model.fit(train_dataset['x'], train_dataset['y'])\n",
    "plotClassification(train_dataset['x'], train_dataset['y'], model, label='Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a546d52e",
   "metadata": {},
   "source": [
    "#### Gaussian SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6bfbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 1.5\n",
    "C=100.\n",
    "kernel = RBF(sigma).kernel\n",
    "model = KernelSVC(C=C, kernel=kernel)\n",
    "train_dataset = datasets['dataset_3']['train']\n",
    "model.fit(train_dataset['x'], train_dataset['y'])\n",
    "plotClassification(train_dataset['x'], train_dataset['y'], model, label='Training')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kernel_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
